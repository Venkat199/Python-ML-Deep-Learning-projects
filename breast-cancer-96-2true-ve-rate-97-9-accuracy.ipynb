{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "postal-salon",
   "metadata": {
    "papermill": {
     "duration": 0.007818,
     "end_time": "2021-05-30T19:36:49.482737",
     "exception": false,
     "start_time": "2021-05-30T19:36:49.474919",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Breast Cancer Dataset \n",
    "The Dataset is obtained from https://www.kaggle.com/uciml/breast-cancer-wisconsin-data/code \n",
    "My aim is to find the model which detects the least number of Malignant diagnosis as Benign. \n",
    "Feature Selection is first done using ANOVA (Analysis of Variance) F-test.\n",
    "Minmax scalar is used.\n",
    "I have tested Logistic Regression and KNNs to find the best model.\n",
    "SMOTE can be used to tackle the imbalanced classes problem.\n",
    "The aim is to find the most relavent Features. \n",
    "It can be observed even by using 1 feature 'concave points_worst', top predictor nearly 90% accuracy can be obtained. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "industrial-salon",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T19:36:49.501149Z",
     "iopub.status.busy": "2021-05-30T19:36:49.500036Z",
     "iopub.status.idle": "2021-05-30T19:36:49.510220Z",
     "shell.execute_reply": "2021-05-30T19:36:49.509566Z",
     "shell.execute_reply.started": "2021-05-30T19:26:19.305274Z"
    },
    "papermill": {
     "duration": 0.020792,
     "end_time": "2021-05-30T19:36:49.510419",
     "exception": false,
     "start_time": "2021-05-30T19:36:49.489627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fuzzy-resort",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T19:36:49.530727Z",
     "iopub.status.busy": "2021-05-30T19:36:49.529997Z",
     "iopub.status.idle": "2021-05-30T19:36:49.571190Z",
     "shell.execute_reply": "2021-05-30T19:36:49.570342Z",
     "shell.execute_reply.started": "2021-05-30T19:26:23.035216Z"
    },
    "papermill": {
     "duration": 0.054201,
     "end_time": "2021-05-30T19:36:49.571358",
     "exception": false,
     "start_time": "2021-05-30T19:36:49.517157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cancer_df = pd.read_csv('../input/breast-cancer-wisconsin-data/data.csv')\n",
    "cancer_df.drop('Unnamed: 32',axis='columns',inplace=True)\n",
    "cancer_df['diagnosis'] = cancer_df['diagnosis'].replace(['M','B'],[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "entitled-maria",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T19:36:49.591771Z",
     "iopub.status.busy": "2021-05-30T19:36:49.590970Z",
     "iopub.status.idle": "2021-05-30T19:36:49.619969Z",
     "shell.execute_reply": "2021-05-30T19:36:49.620460Z",
     "shell.execute_reply.started": "2021-05-30T19:26:28.335566Z"
    },
    "papermill": {
     "duration": 0.042315,
     "end_time": "2021-05-30T19:36:49.620672",
     "exception": false,
     "start_time": "2021-05-30T19:36:49.578357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "malignant    212\n",
       "beign        357\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benign = len(cancer_df[cancer_df['diagnosis'] == 0])\n",
    "malignant = len(cancer_df[cancer_df['diagnosis'] == 1])\n",
    "s = {'malignant':malignant,'beign':benign}\n",
    "pd.Series(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "checked-symposium",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T19:36:49.642921Z",
     "iopub.status.busy": "2021-05-30T19:36:49.642176Z",
     "iopub.status.idle": "2021-05-30T19:36:49.645348Z",
     "shell.execute_reply": "2021-05-30T19:36:49.644829Z",
     "shell.execute_reply.started": "2021-05-30T19:26:31.635469Z"
    },
    "papermill": {
     "duration": 0.016996,
     "end_time": "2021-05-30T19:36:49.645504",
     "exception": false,
     "start_time": "2021-05-30T19:36:49.628508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = cancer_df.drop('diagnosis',axis='columns')\n",
    "y = cancer_df['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "divided-namibia",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T19:36:49.675458Z",
     "iopub.status.busy": "2021-05-30T19:36:49.674695Z",
     "iopub.status.idle": "2021-05-30T19:36:54.444215Z",
     "shell.execute_reply": "2021-05-30T19:36:54.446122Z",
     "shell.execute_reply.started": "2021-05-30T19:26:39.569246Z"
    },
    "papermill": {
     "duration": 4.793683,
     "end_time": "2021-05-30T19:36:54.446462",
     "exception": false,
     "start_time": "2021-05-30T19:36:49.652779",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features in the order of importance\n",
      "\n",
      "['concave points_worst', 'perimeter_worst', 'concave points_mean', 'radius_worst', 'perimeter_mean', 'area_worst', 'radius_mean', 'area_mean', 'concavity_mean', 'concavity_worst', 'compactness_mean', 'compactness_worst', 'radius_se', 'perimeter_se', 'area_se', 'texture_worst', 'smoothness_worst', 'symmetry_worst', 'texture_mean', 'concave points_se', 'smoothness_mean', 'symmetry_mean', 'fractal_dimension_worst', 'compactness_se', 'concavity_se', 'fractal_dimension_se', 'smoothness_se', 'id', 'fractal_dimension_mean', 'texture_se', 'symmetry_se']\n",
      "\n",
      "with top 1 features\n",
      "\n",
      "***Using logistic regression***\n",
      "Train accuracy 0.918\n",
      "Test accuracy 0.909\n",
      "[[87  3]\n",
      " [10 43]]\n",
      "\n",
      "***Using Knn regression***\n",
      "Train accuracy 0.908\n",
      "Test accuracy 0.902\n",
      "[[84  6]\n",
      " [ 8 45]]\n",
      "\n",
      "***Using Smote & logistic regression***\n",
      "Train accuracy 0.901\n",
      "Test accuracy 0.895\n",
      "[[82  8]\n",
      " [ 7 46]]\n",
      "\n",
      "with top 2 features\n",
      "\n",
      "***Using logistic regression***\n",
      "Train accuracy 0.932\n",
      "Test accuracy 0.944\n",
      "[[89  1]\n",
      " [ 7 46]]\n",
      "\n",
      "***Using Knn regression***\n",
      "Train accuracy 0.944\n",
      "Test accuracy 0.944\n",
      "[[86  4]\n",
      " [ 4 49]]\n",
      "\n",
      "***Using Smote & logistic regression***\n",
      "Train accuracy 0.933\n",
      "Test accuracy 0.923\n",
      "[[85  5]\n",
      " [ 6 47]]\n",
      "\n",
      "with top 3 features\n",
      "\n",
      "***Using logistic regression***\n",
      "Train accuracy 0.932\n",
      "Test accuracy 0.944\n",
      "[[89  1]\n",
      " [ 7 46]]\n",
      "\n",
      "***Using Knn regression***\n",
      "Train accuracy 0.937\n",
      "Test accuracy 0.951\n",
      "[[87  3]\n",
      " [ 4 49]]\n",
      "\n",
      "***Using Smote & logistic regression***\n",
      "Train accuracy 0.940\n",
      "Test accuracy 0.930\n",
      "[[86  4]\n",
      " [ 6 47]]\n",
      "\n",
      "with top 4 features\n",
      "\n",
      "***Using logistic regression***\n",
      "Train accuracy 0.941\n",
      "Test accuracy 0.944\n",
      "[[89  1]\n",
      " [ 7 46]]\n",
      "\n",
      "***Using Knn regression***\n",
      "Train accuracy 0.951\n",
      "Test accuracy 0.965\n",
      "[[87  3]\n",
      " [ 2 51]]\n",
      "\n",
      "***Using Smote & logistic regression***\n",
      "Train accuracy 0.944\n",
      "Test accuracy 0.944\n",
      "[[87  3]\n",
      " [ 5 48]]\n",
      "\n",
      "with top 5 features\n",
      "\n",
      "***Using logistic regression***\n",
      "Train accuracy 0.941\n",
      "Test accuracy 0.944\n",
      "[[89  1]\n",
      " [ 7 46]]\n",
      "\n",
      "***Using Knn regression***\n",
      "Train accuracy 0.951\n",
      "Test accuracy 0.965\n",
      "[[89  1]\n",
      " [ 4 49]]\n",
      "\n",
      "***Using Smote & logistic regression***\n",
      "Train accuracy 0.948\n",
      "Test accuracy 0.937\n",
      "[[86  4]\n",
      " [ 5 48]]\n",
      "\n",
      "with top 6 features\n",
      "\n",
      "***Using logistic regression***\n",
      "Train accuracy 0.941\n",
      "Test accuracy 0.951\n",
      "[[89  1]\n",
      " [ 6 47]]\n",
      "\n",
      "***Using Knn regression***\n",
      "Train accuracy 0.953\n",
      "Test accuracy 0.958\n",
      "[[89  1]\n",
      " [ 5 48]]\n",
      "\n",
      "***Using Smote & logistic regression***\n",
      "Train accuracy 0.948\n",
      "Test accuracy 0.944\n",
      "[[86  4]\n",
      " [ 4 49]]\n",
      "\n",
      "with top 7 features\n",
      "\n",
      "***Using logistic regression***\n",
      "Train accuracy 0.932\n",
      "Test accuracy 0.944\n",
      "[[89  1]\n",
      " [ 7 46]]\n",
      "\n",
      "***Using Knn regression***\n",
      "Train accuracy 0.960\n",
      "Test accuracy 0.965\n",
      "[[89  1]\n",
      " [ 4 49]]\n",
      "\n",
      "***Using Smote & logistic regression***\n",
      "Train accuracy 0.948\n",
      "Test accuracy 0.951\n",
      "[[85  5]\n",
      " [ 2 51]]\n",
      "\n",
      "with top 8 features\n",
      "\n",
      "***Using logistic regression***\n",
      "Train accuracy 0.934\n",
      "Test accuracy 0.944\n",
      "[[89  1]\n",
      " [ 7 46]]\n",
      "\n",
      "***Using Knn regression***\n",
      "Train accuracy 0.960\n",
      "Test accuracy 0.965\n",
      "[[89  1]\n",
      " [ 4 49]]\n",
      "\n",
      "***Using Smote & logistic regression***\n",
      "Train accuracy 0.948\n",
      "Test accuracy 0.951\n",
      "[[85  5]\n",
      " [ 2 51]]\n",
      "\n",
      "with top 9 features\n",
      "\n",
      "***Using logistic regression***\n",
      "Train accuracy 0.944\n",
      "Test accuracy 0.944\n",
      "[[89  1]\n",
      " [ 7 46]]\n",
      "\n",
      "***Using Knn regression***\n",
      "Train accuracy 0.955\n",
      "Test accuracy 0.944\n",
      "[[87  3]\n",
      " [ 5 48]]\n",
      "\n",
      "***Using Smote & logistic regression***\n",
      "Train accuracy 0.946\n",
      "Test accuracy 0.951\n",
      "[[85  5]\n",
      " [ 2 51]]\n",
      "\n",
      "with top 10 features\n",
      "\n",
      "***Using logistic regression***\n",
      "Train accuracy 0.941\n",
      "Test accuracy 0.958\n",
      "[[90  0]\n",
      " [ 6 47]]\n",
      "\n",
      "***Using Knn regression***\n",
      "Train accuracy 0.953\n",
      "Test accuracy 0.944\n",
      "[[86  4]\n",
      " [ 4 49]]\n",
      "\n",
      "***Using Smote & logistic regression***\n",
      "Train accuracy 0.946\n",
      "Test accuracy 0.923\n",
      "[[83  7]\n",
      " [ 4 49]]\n",
      "\n",
      "with top 11 features\n",
      "\n",
      "***Using logistic regression***\n",
      "Train accuracy 0.941\n",
      "Test accuracy 0.944\n",
      "[[88  2]\n",
      " [ 6 47]]\n",
      "\n",
      "***Using Knn regression***\n",
      "Train accuracy 0.953\n",
      "Test accuracy 0.944\n",
      "[[87  3]\n",
      " [ 5 48]]\n",
      "\n",
      "***Using Smote & logistic regression***\n",
      "Train accuracy 0.944\n",
      "Test accuracy 0.923\n",
      "[[83  7]\n",
      " [ 4 49]]\n",
      "\n",
      "with top 12 features\n",
      "\n",
      "***Using logistic regression***\n",
      "Train accuracy 0.946\n",
      "Test accuracy 0.937\n",
      "[[87  3]\n",
      " [ 6 47]]\n",
      "\n",
      "***Using Knn regression***\n",
      "Train accuracy 0.960\n",
      "Test accuracy 0.930\n",
      "[[85  5]\n",
      " [ 5 48]]\n",
      "\n",
      "***Using Smote & logistic regression***\n",
      "Train accuracy 0.948\n",
      "Test accuracy 0.916\n",
      "[[83  7]\n",
      " [ 5 48]]\n",
      "\n",
      "with top 13 features\n",
      "\n",
      "***Using logistic regression***\n",
      "Train accuracy 0.946\n",
      "Test accuracy 0.937\n",
      "[[87  3]\n",
      " [ 6 47]]\n",
      "\n",
      "***Using Knn regression***\n",
      "Train accuracy 0.955\n",
      "Test accuracy 0.923\n",
      "[[84  6]\n",
      " [ 5 48]]\n",
      "\n",
      "***Using Smote & logistic regression***\n",
      "Train accuracy 0.946\n",
      "Test accuracy 0.916\n",
      "[[83  7]\n",
      " [ 5 48]]\n",
      "\n",
      "with top 14 features\n",
      "\n",
      "***Using logistic regression***\n",
      "Train accuracy 0.946\n",
      "Test accuracy 0.937\n",
      "[[87  3]\n",
      " [ 6 47]]\n",
      "\n",
      "***Using Knn regression***\n",
      "Train accuracy 0.948\n",
      "Test accuracy 0.916\n",
      "[[84  6]\n",
      " [ 6 47]]\n",
      "\n",
      "***Using Smote & logistic regression***\n",
      "Train accuracy 0.948\n",
      "Test accuracy 0.923\n",
      "[[84  6]\n",
      " [ 5 48]]\n",
      "\n",
      "with top 15 features\n",
      "\n",
      "***Using logistic regression***\n",
      "Train accuracy 0.946\n",
      "Test accuracy 0.937\n",
      "[[87  3]\n",
      " [ 6 47]]\n",
      "\n",
      "***Using Knn regression***\n",
      "Train accuracy 0.948\n",
      "Test accuracy 0.916\n",
      "[[84  6]\n",
      " [ 6 47]]\n",
      "\n",
      "***Using Smote & logistic regression***\n",
      "Train accuracy 0.948\n",
      "Test accuracy 0.923\n",
      "[[84  6]\n",
      " [ 5 48]]\n",
      "\n",
      "with top 16 features\n",
      "\n",
      "***Using logistic regression***\n",
      "Train accuracy 0.955\n",
      "Test accuracy 0.958\n",
      "[[89  1]\n",
      " [ 5 48]]\n",
      "\n",
      "***Using Knn regression***\n",
      "Train accuracy 0.965\n",
      "Test accuracy 0.979\n",
      "[[89  1]\n",
      " [ 2 51]]\n",
      "\n",
      "***Using Smote & logistic regression***\n",
      "Train accuracy 0.963\n",
      "Test accuracy 0.944\n",
      "[[85  5]\n",
      " [ 3 50]]\n",
      "\n",
      "with top 17 features\n",
      "\n",
      "***Using logistic regression***\n",
      "Train accuracy 0.958\n",
      "Test accuracy 0.958\n",
      "[[90  0]\n",
      " [ 6 47]]\n",
      "\n",
      "***Using Knn regression***\n",
      "Train accuracy 0.977\n",
      "Test accuracy 0.979\n",
      "[[89  1]\n",
      " [ 2 51]]\n",
      "\n",
      "***Using Smote & logistic regression***\n",
      "Train accuracy 0.964\n",
      "Test accuracy 0.972\n",
      "[[88  2]\n",
      " [ 2 51]]\n",
      "\n",
      "with top 18 features\n",
      "\n",
      "***Using logistic regression***\n",
      "Train accuracy 0.958\n",
      "Test accuracy 0.965\n",
      "[[90  0]\n",
      " [ 5 48]]\n",
      "\n",
      "***Using Knn regression***\n",
      "Train accuracy 0.979\n",
      "Test accuracy 0.965\n",
      "[[88  2]\n",
      " [ 3 50]]\n",
      "\n",
      "***Using Smote & logistic regression***\n",
      "Train accuracy 0.974\n",
      "Test accuracy 0.958\n",
      "[[87  3]\n",
      " [ 3 50]]\n",
      "\n",
      "with top 19 features\n",
      "\n",
      "***Using logistic regression***\n",
      "Train accuracy 0.967\n",
      "Test accuracy 0.965\n",
      "[[90  0]\n",
      " [ 5 48]]\n",
      "\n",
      "***Using Knn regression***\n",
      "Train accuracy 0.979\n",
      "Test accuracy 0.951\n",
      "[[87  3]\n",
      " [ 4 49]]\n",
      "\n",
      "***Using Smote & logistic regression***\n",
      "Train accuracy 0.968\n",
      "Test accuracy 0.979\n",
      "[[89  1]\n",
      " [ 2 51]]\n",
      "\n",
      "with top 20 features\n",
      "\n",
      "***Using logistic regression***\n",
      "Train accuracy 0.967\n",
      "Test accuracy 0.965\n",
      "[[90  0]\n",
      " [ 5 48]]\n",
      "\n",
      "***Using Knn regression***\n",
      "Train accuracy 0.979\n",
      "Test accuracy 0.958\n",
      "[[88  2]\n",
      " [ 4 49]]\n",
      "\n",
      "***Using Smote & logistic regression***\n",
      "Train accuracy 0.966\n",
      "Test accuracy 0.979\n",
      "[[89  1]\n",
      " [ 2 51]]\n",
      "\n",
      "with top 21 features\n",
      "\n",
      "***Using logistic regression***\n",
      "Train accuracy 0.965\n",
      "Test accuracy 0.965\n",
      "[[90  0]\n",
      " [ 5 48]]\n",
      "\n",
      "***Using Knn regression***\n",
      "Train accuracy 0.977\n",
      "Test accuracy 0.965\n",
      "[[89  1]\n",
      " [ 4 49]]\n",
      "\n",
      "***Using Smote & logistic regression***\n",
      "Train accuracy 0.974\n",
      "Test accuracy 0.972\n",
      "[[89  1]\n",
      " [ 3 50]]\n",
      "\n",
      "with top 22 features\n",
      "\n",
      "***Using logistic regression***\n",
      "Train accuracy 0.965\n",
      "Test accuracy 0.965\n",
      "[[90  0]\n",
      " [ 5 48]]\n",
      "\n",
      "***Using Knn regression***\n",
      "Train accuracy 0.977\n",
      "Test accuracy 0.965\n",
      "[[89  1]\n",
      " [ 4 49]]\n",
      "\n",
      "***Using Smote & logistic regression***\n",
      "Train accuracy 0.974\n",
      "Test accuracy 0.965\n",
      "[[88  2]\n",
      " [ 3 50]]\n",
      "\n",
      "with top 23 features\n",
      "\n",
      "***Using logistic regression***\n",
      "Train accuracy 0.965\n",
      "Test accuracy 0.965\n",
      "[[90  0]\n",
      " [ 5 48]]\n",
      "\n",
      "***Using Knn regression***\n",
      "Train accuracy 0.979\n",
      "Test accuracy 0.958\n",
      "[[88  2]\n",
      " [ 4 49]]\n",
      "\n",
      "***Using Smote & logistic regression***\n",
      "Train accuracy 0.976\n",
      "Test accuracy 0.965\n",
      "[[88  2]\n",
      " [ 3 50]]\n",
      "\n",
      "with top 24 features\n",
      "\n",
      "***Using logistic regression***\n",
      "Train accuracy 0.972\n",
      "Test accuracy 0.965\n",
      "[[90  0]\n",
      " [ 5 48]]\n",
      "\n",
      "***Using Knn regression***\n",
      "Train accuracy 0.977\n",
      "Test accuracy 0.965\n",
      "[[89  1]\n",
      " [ 4 49]]\n",
      "\n",
      "***Using Smote & logistic regression***\n",
      "Train accuracy 0.974\n",
      "Test accuracy 0.972\n",
      "[[89  1]\n",
      " [ 3 50]]\n",
      "\n",
      "with top 25 features\n",
      "\n",
      "***Using logistic regression***\n",
      "Train accuracy 0.972\n",
      "Test accuracy 0.965\n",
      "[[90  0]\n",
      " [ 5 48]]\n",
      "\n",
      "***Using Knn regression***\n",
      "Train accuracy 0.977\n",
      "Test accuracy 0.965\n",
      "[[89  1]\n",
      " [ 4 49]]\n",
      "\n",
      "***Using Smote & logistic regression***\n",
      "Train accuracy 0.972\n",
      "Test accuracy 0.972\n",
      "[[89  1]\n",
      " [ 3 50]]\n",
      "\n",
      "with top 26 features\n",
      "\n",
      "***Using logistic regression***\n",
      "Train accuracy 0.969\n",
      "Test accuracy 0.965\n",
      "[[90  0]\n",
      " [ 5 48]]\n",
      "\n",
      "***Using Knn regression***\n",
      "Train accuracy 0.977\n",
      "Test accuracy 0.958\n",
      "[[89  1]\n",
      " [ 5 48]]\n",
      "\n",
      "***Using Smote & logistic regression***\n",
      "Train accuracy 0.972\n",
      "Test accuracy 0.972\n",
      "[[89  1]\n",
      " [ 3 50]]\n",
      "\n",
      "with top 27 features\n",
      "\n",
      "***Using logistic regression***\n",
      "Train accuracy 0.969\n",
      "Test accuracy 0.958\n",
      "[[90  0]\n",
      " [ 6 47]]\n",
      "\n",
      "***Using Knn regression***\n",
      "Train accuracy 0.974\n",
      "Test accuracy 0.958\n",
      "[[89  1]\n",
      " [ 5 48]]\n",
      "\n",
      "***Using Smote & logistic regression***\n",
      "Train accuracy 0.972\n",
      "Test accuracy 0.972\n",
      "[[89  1]\n",
      " [ 3 50]]\n",
      "\n",
      "with top 28 features\n",
      "\n",
      "***Using logistic regression***\n",
      "Train accuracy 0.969\n",
      "Test accuracy 0.958\n",
      "[[90  0]\n",
      " [ 6 47]]\n",
      "\n",
      "***Using Knn regression***\n",
      "Train accuracy 0.974\n",
      "Test accuracy 0.958\n",
      "[[89  1]\n",
      " [ 5 48]]\n",
      "\n",
      "***Using Smote & logistic regression***\n",
      "Train accuracy 0.972\n",
      "Test accuracy 0.965\n",
      "[[89  1]\n",
      " [ 4 49]]\n",
      "\n",
      "with top 29 features\n",
      "\n",
      "***Using logistic regression***\n",
      "Train accuracy 0.974\n",
      "Test accuracy 0.958\n",
      "[[90  0]\n",
      " [ 6 47]]\n",
      "\n",
      "***Using Knn regression***\n",
      "Train accuracy 0.974\n",
      "Test accuracy 0.958\n",
      "[[89  1]\n",
      " [ 5 48]]\n",
      "\n",
      "***Using Smote & logistic regression***\n",
      "Train accuracy 0.974\n",
      "Test accuracy 0.958\n",
      "[[88  2]\n",
      " [ 4 49]]\n",
      "\n",
      "with top 30 features\n",
      "\n",
      "***Using logistic regression***\n",
      "Train accuracy 0.974\n",
      "Test accuracy 0.958\n",
      "[[90  0]\n",
      " [ 6 47]]\n",
      "\n",
      "***Using Knn regression***\n",
      "Train accuracy 0.977\n",
      "Test accuracy 0.958\n",
      "[[89  1]\n",
      " [ 5 48]]\n",
      "\n",
      "***Using Smote & logistic regression***\n",
      "Train accuracy 0.974\n",
      "Test accuracy 0.965\n",
      "[[89  1]\n",
      " [ 4 49]]\n",
      "\n",
      "with top 31 features\n",
      "\n",
      "***Using logistic regression***\n",
      "Train accuracy 0.974\n",
      "Test accuracy 0.958\n",
      "[[90  0]\n",
      " [ 6 47]]\n",
      "\n",
      "***Using Knn regression***\n",
      "Train accuracy 0.977\n",
      "Test accuracy 0.958\n",
      "[[89  1]\n",
      " [ 5 48]]\n",
      "\n",
      "***Using Smote & logistic regression***\n",
      "Train accuracy 0.976\n",
      "Test accuracy 0.972\n",
      "[[89  1]\n",
      " [ 3 50]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X = cancer_df.drop('diagnosis',axis='columns')\n",
    "y = cancer_df['diagnosis']\n",
    "test = SelectKBest(score_func=f_classif)\n",
    "fit = test.fit(X, y)\n",
    "scores = fit.scores_\n",
    "indices = (-scores).argsort()\n",
    "feature_cols = list(X.columns)\n",
    "feature_cols = [feature_cols[i] for i in indices]   # Feature columns arranged in the order of Importance\n",
    "print('Features in the order of importance\\n')\n",
    "print(feature_cols)\n",
    "scores = fit.scores_\n",
    "scaler = MinMaxScaler()\n",
    "for i in range(1,32):\n",
    "    print('\\nwith top {} features\\n'.format(i))\n",
    "    X_selected_features = X[feature_cols[0:i]]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_selected_features, y, random_state=0)\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    logistic = LogisticRegression(penalty='l2')\n",
    "    logistic.fit(X_train, y_train)\n",
    "    logistic.fit(X_train, y_train)\n",
    "    knn = KNeighborsClassifier(n_neighbors=5,weights='uniform')\n",
    "    knn.fit(X_train, y_train)\n",
    "    print('***Using logistic regression***')\n",
    "    print('Train accuracy {:.3f}'.format(logistic.score(X_train,y_train)))\n",
    "    print('Test accuracy {:.3f}'.format(logistic.score(X_test,y_test)))\n",
    "    print(confusion_matrix(y_test, logistic.predict(X_test)))\n",
    "    print('\\n***Using Knn regression***')\n",
    "    print('Train accuracy {:.3f}'.format(knn.score(X_train,y_train)))\n",
    "    print('Test accuracy {:.3f}'.format(knn.score(X_test,y_test)))\n",
    "    print(confusion_matrix(y_test, knn.predict(X_test)))\n",
    "    oversample = SMOTE(random_state=0)\n",
    "    X_smote_train, y_smote_train = oversample.fit_resample(X_train, y_train)\n",
    "    logistic.fit(X_smote_train, y_smote_train)\n",
    "    print('\\n***Using Smote & logistic regression***')\n",
    "    print('Train accuracy {:.3f}'.format(logistic.score(X_smote_train,y_smote_train)))\n",
    "    print('Test accuracy {:.3f}'.format(logistic.score(X_test,y_test)))\n",
    "    print(confusion_matrix(y_test, logistic.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "steady-estate",
   "metadata": {
    "papermill": {
     "duration": 0.022054,
     "end_time": "2021-05-30T19:36:54.492894",
     "exception": false,
     "start_time": "2021-05-30T19:36:54.470840",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It can be Observed that using top 16 Features and KNN with 5 neighbours and uniform weights, False Negatives (Malignant as Benign)  are least.\n",
    "Max Test set accuracy Observed is 97.9 % \n",
    "With True Positive Rate of 96.2 % in 2 cases\n",
    "KNN with 5 nearest neighbours and top 16 features with uniform weights.\n",
    "Logistic regression with L2 penalty, top 19 features and SMOTE over sampling to tackle the Class Imbalance. This model can be considered as the best model for this use case.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14.829741,
   "end_time": "2021-05-30T19:36:55.536051",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-30T19:36:40.706310",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
